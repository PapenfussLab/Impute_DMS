{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d361e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file '/Users/fu.j/.matplotlib/matplotlibrc', line 2 ('backend: TkAgg')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "import util as util\n",
    "from factorisedms import impute_by_matrix_factorisation\n",
    "from aalasso import linear_collaborative_filtering_on_rows_lasso\n",
    "from wu2019.wu_modify import foo_wu2019_wrapping_func_23031601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87555e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMS_ENVF = pd.read_csv('../data/dms_envfeat_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e8467",
   "metadata": {},
   "source": [
    "# Benchmark AALasso, FactoriseDMS, Envision and Wu2019 methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba3509",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88375e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo_make_featured_data_23031601(input_data):\n",
    "    dms_envf_all = input_data.copy()\n",
    "    dms_envf_all['wt_mut'] = dms_envf_all['aa1'] + dms_envf_all['aa2']  # NA was assumed as missing.\n",
    "    env_feats = ['aa1', 'aa2', 'wt_mut', 'aa1_polarity', 'aa2_polarity', 'aa1_PI', 'aa2_PI', \n",
    "                 'deltaPI', 'aa1_weight', 'aa2_weight', 'deltaWeight', 'aa1vol', 'aa2vol', \n",
    "                 'deltavolume', 'Grantham', 'aa1_psic', 'aa2_psic', 'delta_psic', 'accessibility', \n",
    "                 'dssp_sec_str', 'phi_psi_reg', 'delta_solvent_accessibility', 'b_factor', \n",
    "                 'mut_msa_congruency', 'mut_mut_msa_congruency', 'seq_ind_closest_mut', \n",
    "                 'evolutionary_coupling_avg']\n",
    "    categ_feat = ['aa1', 'aa2', 'wt_mut', 'aa1_polarity', 'aa2_polarity', 'dssp_sec_str', 'phi_psi_reg']\n",
    "    numer_feat = [x for x in env_feats if x not in categ_feat]\n",
    "    dms_envf_all = util.impute_missing_value(dms_envf_all, categ_feat, numer_feat)\n",
    "    dms_envf_all, encoded_col = util.encode_categorical_feature(dms_envf_all, categ_feat, ['aa1', 'aa2'])\n",
    "    env_encfeat = encoded_col + numer_feat\n",
    "\n",
    "    wu_feature = []\n",
    "    blosum = pd.read_csv('../src/wu2019/database/humandb/dms/other_features/blosums.csv')\n",
    "    blosum = blosum[['aa_ref', 'aa_alt', 'blosum100']]\n",
    "    folder = '../src/wu2019/database/humandb/dms/features/'\n",
    "    for unip in dms_envf_all.uniprot_id.unique():\n",
    "        file = f\"{folder}{unip}_features.csv\"\n",
    "        if os.path.isfile(file):\n",
    "            data = pd.read_csv(file)\n",
    "            data['uniprot_id'] = unip\n",
    "            wu_feature.append(data)\n",
    "    wu_feature = pd.concat(wu_feature, ignore_index=True)\n",
    "    wu_feature = pd.merge(wu_feature, blosum, on=['aa_ref', 'aa_alt'], how='left', validate='m:1')\n",
    "    wu_feature = wu_feature[['polyphen_score', 'provean_score', 'blosum100', 'aa_alt', 'aa_ref', 'aa_pos', 'uniprot_id']]\n",
    "    wu_feature = wu_feature.rename(columns={'aa_alt': 'aa2', 'aa_ref': 'aa1', 'aa_pos': 'u_pos'})\n",
    "    \n",
    "    dms_envwu_all = pd.merge(dms_envf_all, wu_feature, on=['uniprot_id', 'u_pos', 'aa1', 'aa2'], how='left', \n",
    "                             validate='m:1')\n",
    "    dms_envwu_all = util.impute_missing_value(dms_envwu_all, None, ['polyphen_score', 'provean_score', 'blosum100'])\n",
    "    \n",
    "    return dms_envwu_all, env_encfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0921410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_ens_feat = ['envision_pred', 'lasso_pred', 'fdms_pred', 'row-mean_pred', 'wu2019_pred', \n",
    "                  'polyphen_score', 'provean_score', 'blosum100']  # Seems that Wu2019 only use these features?\n",
    "ens_params = {'n_estimators': [100, 200, 500], 'max_depth': [5, 10, 50], 'min_weight_fraction_leaf': [0, 0.01, 0.1]}\n",
    "env_params = {'max_features': [0.1, 0.5, None], 'max_depth': [3, 7, 15], 'min_weight_fraction_leaf': [0, 0.001, 0.01]}\n",
    "\n",
    "dms_envwu_all, env_encfeat = foo_make_featured_data_23031601(DMS_ENVF)\n",
    "wu_ava_unip = pd.read_csv('../src/wu2019/projects/imputation/gwt/www/downloads/supported_uniprot_ids.txt',\n",
    "                  sep='\\t')\n",
    "wu_ava_unip = set(wu_ava_unip.UniProtID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b001b6",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../result/benchmark_ensemble/'\n",
    "aalasso_dir = '../result/aalasso/'\n",
    "\n",
    "sess_prefix = 'env_tune'\n",
    "for dms_id in dms_envwu_all.dms_id.unique():\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    dms_data = dms_envwu_all.query(\"dms_id == @dms_id\")\n",
    "    for rep in range(5):\n",
    "        tr_data, te_data = train_test_split(dms_data, test_size=0.1, random_state=seed+rep, shuffle=True)\n",
    "\n",
    "        cv_data = {'full': {'tr': tr_data, 'te': te_data}}\n",
    "        for cv_key, (train_cv, valid_cv) in enumerate(KFold(10, random_state=seed+rep, shuffle=True).split(tr_data)):\n",
    "            cv_data[cv_key] = {'tr': tr_data.iloc[train_cv], 'te': tr_data.iloc[valid_cv]}\n",
    "\n",
    "        for cv_key, data in cv_data.items():\n",
    "            train_cv = data['tr']\n",
    "            valid_cv = data['te']\n",
    "            valid_cv['cv'] = cv_key\n",
    "\n",
    "            # Add residues only available in the validation data. This is necessary for certain models when the data \n",
    "            # is exremely sparse.\n",
    "            va_only_pos = set(valid_cv.position) - set(train_cv.position)\n",
    "            if len(va_only_pos) > 0:\n",
    "                va_only_wt = valid_cv.query(\"position in @va_only_pos\")[['dms_id', 'position', 'u_pos',\n",
    "                                                                         'aa1']].drop_duplicates().copy()\n",
    "                va_only_wt['aa2'] = va_only_wt['aa1']\n",
    "                va_only_wt['score'] = 1\n",
    "                train_cv_va_wt = pd.concat([train_cv, va_only_wt], ignore_index=True)\n",
    "                mask_mat = util.create_dms_score_matrix(train_cv_va_wt, 1)\n",
    "            else:\n",
    "                train_cv_va_wt = train_cv.copy()\n",
    "                mask_mat = util.create_dms_score_matrix(train_cv, 1)\n",
    "\n",
    "            # Individual imputation methods.\n",
    "            for method in ['envision', 'wu2019', 'lasso', 'fdms', 'row-mean']:\n",
    "                if method == 'envision':\n",
    "                    estimator = GradientBoostingRegressor(random_state=seed+rep)\n",
    "                    gs = GridSearchCV(estimator, env_params)\n",
    "                    estimator = gs.fit(train_cv[env_encfeat], train_cv['score']).best_estimator_\n",
    "                    valid_cv['envision_pred'] = estimator.predict(valid_cv[env_encfeat])\n",
    "                    if cv_key == 'full':\n",
    "                        top_feat = list(pd.Series(dict(zip(env_encfeat, \n",
    "                                                           estimator.feature_importances_))).sort_values().tail(10).index)\n",
    "                        ens_feat = basic_ens_feat + top_feat\n",
    "\n",
    "                elif method == 'wu2019':\n",
    "                    uniprot_id = train_cv['uniprot_id'].iloc[0]\n",
    "                    if uniprot_id not in wu_ava_unip:\n",
    "                        valid_cv['wu2019_pred'] = 1  # Can not be imputed so just set wildtype arbitrarily.\n",
    "                    else:\n",
    "                        imp_result = foo_wu2019_wrapping_func_23031601(train_cv_va_wt, f\"{sess_prefix}_{dms_id}_{rep}_{cv_key}\")\n",
    "                        imp_result = imp_result.rename(columns={'pred_score': 'wu2019_pred'})\n",
    "                        valid_cv = pd.merge(valid_cv, imp_result, on=['u_pos', 'aa2'], how='left', validate='1:1')\n",
    "\n",
    "                else:\n",
    "                    if method == 'lasso':\n",
    "                        if cv_key == 'full':\n",
    "                            coef_file = f\"{aalasso_dir}{dms_id}_{rep}_coef.csv\"\n",
    "                        else:\n",
    "                            coef_file = None\n",
    "                        imp_mat = linear_collaborative_filtering_on_rows_lasso(mask_mat, 'ACDEFGHIKLMNPQRSTVWY', \n",
    "                                                                               0.01, seed+rep, coef_file)\n",
    "                    elif method == 'fdms':\n",
    "                        imp_mat = impute_by_matrix_factorisation(mask_mat, seed+rep, 100, n_components=2, \n",
    "                                                                           regularization=1)\n",
    "                    elif method == 'row-mean':\n",
    "                        null_mat = mask_mat.copy()\n",
    "                        null_mat.loc[:,:] = np.nan\n",
    "                        imp_mat = null_mat.T.fillna(mask_mat.mean(axis=1)).T\n",
    "                    else:\n",
    "                        raise ValueError()\n",
    "                    imp_long = imp_mat.reset_index().melt(id_vars=['dms_id', 'position'], value_name=f\"{method}_pred\", \n",
    "                                                          var_name='aa2')\n",
    "                    valid_cv = pd.merge(valid_cv, imp_long, on=['dms_id', 'position', 'aa2'], how='left', validate='1:1')\n",
    "\n",
    "            cv_data[cv_key]['te'] = valid_cv\n",
    "        # Ensemble method.\n",
    "        tr_pred = pd.concat([cv_data[i]['te'] for i in range(10)], ignore_index=True)\n",
    "        te_pred = cv_data['full']['te']\n",
    "        estimator = RandomForestRegressor(random_state=seed+rep, n_jobs=2)\n",
    "        gs = GridSearchCV(estimator, ens_params)\n",
    "        estimator = gs.fit(tr_pred[ens_feat], tr_pred['score']).best_estimator_\n",
    "        tr_pred['pred_score'] = estimator.predict(tr_pred[ens_feat])\n",
    "        te_pred['pred_score'] = estimator.predict(te_pred[ens_feat])\n",
    "\n",
    "        tr_pred.to_csv(f\"{output_dir}{dms_id}_{rep}_enstrain_data.csv\")\n",
    "        te_pred.to_csv(f\"{output_dir}{dms_id}_{rep}_enstest_data.csv\")\n",
    "        tuned_hp = pd.Series(estimator.get_params()).loc[list(ens_params.keys())]\n",
    "        tuned_hp.to_csv(f\"{output_dir}{dms_id}_{rep}_enstrain_hp.csv\")\n",
    "        imp = pd.Series(dict(zip(ens_feat, estimator.feature_importances_)))\n",
    "        imp.to_csv(f\"{output_dir}{dms_id}_{rep}_enstrain_imp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38523b13",
   "metadata": {},
   "source": [
    "## Measure benchmark performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "792acc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envision features are not available for these proteins according to their website.\n",
    "no_envision = ['A0A3G4RHW3', 'Q45996', 'P02829', 'P02943', 'P06654', \n",
    "               'P0ABQ4', 'P0DP23', 'P31016', 'P40515', 'P42212', 'P62593',\n",
    "               'Q06851', 'P62554', 'Q14524']\n",
    "no_env_dms = dms_envwu_all.query(\"uniprot_id in @no_envision\")['dms_id'].unique()\n",
    "\n",
    "envtune_dir = '../result/benchmark_ensemble/'\n",
    "bench_perf = []\n",
    "for file in os.listdir(envtune_dir):\n",
    "    if file[-16:] != 'enstest_data.csv':\n",
    "        continue\n",
    "    \n",
    "    enstest = pd.read_csv(f\"{envtune_dir}{file}\", index_col=0)\n",
    "    dms_id, rep, _, _ = file.split('_')\n",
    "    \n",
    "    eval_dict = {'dms_id': dms_id, 'repeat': rep}\n",
    "    for method in ['envision', 'wu2019', 'lasso', 'fdms', 'row-mean', 'ensemble']:\n",
    "        if method == 'ensemble':\n",
    "            pred_col = 'pred_score'\n",
    "        else:\n",
    "            pred_col = f\"{method}_pred\"\n",
    "            \n",
    "        if (method == 'envision') & (dms_id in no_env_dms):\n",
    "            eval_dict[f\"{method}_spear\"] = eval_dict[f\"{method}_pears\"] = eval_dict[f\"{method}_rmse\"] = np.nan\n",
    "        else:\n",
    "            eval_dict[f\"{method}_spear\"] = spearmanr(enstest['score'], enstest[pred_col])[0]\n",
    "            eval_dict[f\"{method}_pears\"] = pearsonr(enstest['score'], enstest[pred_col])[0]\n",
    "            eval_dict[f\"{method}_rmse\"] = np.sqrt(mean_squared_error(enstest['score'], enstest[pred_col]))\n",
    "    bench_perf.append(eval_dict)\n",
    "bench_perf = pd.DataFrame(bench_perf)\n",
    "#bench_perf.to_csv(f'{envtune_dir}performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6a6ea",
   "metadata": {},
   "source": [
    "## Compute the absolute mean of AALasso coefficient values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8faf1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../result/aalasso/'\n",
    "coef_sum = None\n",
    "count = 0\n",
    "for file_name in os.listdir(root):\n",
    "    if file_name[-8:] != 'coef.csv':\n",
    "        continue\n",
    "    dms, rep, _ = file_name.split('_')\n",
    "    if coef_sum is None:\n",
    "        coef_sum = pd.read_csv(f\"{root}{file_name}\", index_col=0).abs()\n",
    "    else:\n",
    "        coef_sum = coef_sum + pd.read_csv(f\"{root}{file_name}\", index_col=0).abs()\n",
    "    count += 1\n",
    "coef_sum = (coef_sum / count).copy()\n",
    "#coef_sum.to_csv(f'{root}coef_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dee0db",
   "metadata": {},
   "source": [
    "# Performance with different trianing data proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf708dc",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb04a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dms_envf = DMS_ENVF.copy()\n",
    "\n",
    "# Envision features are not available for these proteins according to their website.\n",
    "no_envision = ['A0A3G4RHW3', 'Q45996', 'P02829', 'P02943', 'P06654', \n",
    "               'P0ABQ4', 'P0DP23', 'P31016', 'P40515', 'P42212', 'P62593',\n",
    "               'Q06851', 'P62554', 'Q14524']\n",
    "dms_envf = dms_envf.query(\"uniprot_id not in @no_envision\")\n",
    "dms_envf['wt_mut'] = dms_envf['aa1'] + dms_envf['aa2']  # NA was assumed as missing.\n",
    "\n",
    "env_feats = ['aa1', 'aa2', 'wt_mut', 'aa1_polarity', 'aa2_polarity', 'aa1_PI', 'aa2_PI', \n",
    "             'deltaPI', 'aa1_weight', 'aa2_weight', 'deltaWeight', 'aa1vol', 'aa2vol', \n",
    "             'deltavolume', 'Grantham', 'aa1_psic', 'aa2_psic', 'delta_psic', 'accessibility', \n",
    "             'dssp_sec_str', 'phi_psi_reg', 'delta_solvent_accessibility', 'b_factor', \n",
    "             'mut_msa_congruency', 'mut_mut_msa_congruency', 'seq_ind_closest_mut', \n",
    "             'evolutionary_coupling_avg']\n",
    "categ_feat = ['aa1', 'aa2', 'wt_mut', 'aa1_polarity', 'aa2_polarity', 'dssp_sec_str', 'phi_psi_reg']\n",
    "numer_feat = [x for x in env_feats if x not in categ_feat]\n",
    "\n",
    "dms_envf = util.impute_missing_value(dms_envf, categ_feat, numer_feat)\n",
    "dms_envf, encoded_col = util.encode_categorical_feature(dms_envf, categ_feat, ['aa1', 'aa2'])\n",
    "env_encfeat = encoded_col + numer_feat\n",
    "\n",
    "dms_complete = dict()\n",
    "for dms, data in dms_envf.groupby('dms_id'):\n",
    "    dms_complete[dms] = len(data) / (len(data.u_pos.unique()) * 19)\n",
    "pick_dms = pd.Series(dms_complete)\n",
    "pick_dms = pick_dms[pick_dms>=(18/19)]\n",
    "pick_dms = list(pick_dms.index)\n",
    "pick_dms_data = dms_envf.query(\"dms_id in @pick_dms\").copy()\n",
    "wu_ava_unip = pd.read_csv('../src/wu2019/projects/imputation/gwt/www/downloads/supported_uniprot_ids.txt',\n",
    "                  sep='\\t')\n",
    "wu_ava_unip = set(wu_ava_unip.UniProtID)\n",
    "pick_dms_data = pick_dms_data.query(\"uniprot_id in @wu_ava_unip\")\n",
    "\n",
    "wu_feature = []\n",
    "blosum = pd.read_csv('../src/wu2019/database/humandb/dms/other_features/blosums.csv')\n",
    "blosum = blosum[['aa_ref', 'aa_alt', 'blosum100']]\n",
    "folder = '../src/wu2019/database/humandb/dms/features/'\n",
    "for unip in dms_envf.uniprot_id.unique():\n",
    "    file = f\"{folder}{unip}_features.csv\"\n",
    "    if os.path.isfile(file):\n",
    "        data = pd.read_csv(file)\n",
    "        data['uniprot_id'] = unip\n",
    "        wu_feature.append(data)\n",
    "wu_feature = pd.concat(wu_feature, ignore_index=True)\n",
    "wu_feature = pd.merge(wu_feature, blosum, on=['aa_ref', 'aa_alt'], how='left', validate='m:1')\n",
    "wu_feature = wu_feature[['polyphen_score', 'provean_score', 'blosum100', 'aa_alt', 'aa_ref', 'aa_pos', 'uniprot_id']]\n",
    "wu_feature = wu_feature.rename(columns={'aa_alt': 'aa2', 'aa_ref': 'aa1', 'aa_pos': 'u_pos'})\n",
    "\n",
    "pick_dms_data = pd.merge(pick_dms_data, wu_feature, on=['uniprot_id', 'u_pos', 'aa1', 'aa2'], how='left', \n",
    "                         validate='m:1')\n",
    "pick_dms_data = util.impute_missing_value(pick_dms_data, None, ['polyphen_score', 'provean_score', 'blosum100'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec579a7",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ef1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_ratio_vs_full = 0.1\n",
    "\n",
    "sess_prefix = 'env_tune'\n",
    "basic_ens_feat = ['envision_pred', 'lasso_pred', 'fdms_pred', 'row-mean_pred', 'wu2019_pred', \n",
    "                  'polyphen_score', 'provean_score', 'blosum100']  # Seems that Wu2019 only use these features?\n",
    "ens_params = {'n_estimators': [100, 200, 500], 'max_depth': [5, 10, 50], 'min_weight_fraction_leaf': [0, 0.01, 0.1]}\n",
    "env_params = {'max_features': [0.1, 0.5, None], 'max_depth': [3, 7, 15], 'min_weight_fraction_leaf': [0, 0.001, 0.01]}\n",
    "output_dir = '../result/train_proportion/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8091770",
   "metadata": {},
   "outputs": [],
   "source": [
    "for work_dms in pick_dms_data.dms_id.unique():\n",
    "    for tr_ratio_vs_full in np.arange(0.1,1,0.1):\n",
    "\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        completeness_perf = []\n",
    "        dms = work_dms\n",
    "        dms_data = pick_dms_data.query(\"dms_id==@dms\")\n",
    "        completeness = dms_complete[dms]\n",
    "        for rep in range(5):\n",
    "            test_size = te_ratio_vs_full\n",
    "            tr_data_all, te_data = train_test_split(dms_data, test_size=test_size, random_state=seed+rep, shuffle=True)\n",
    "\n",
    "            if tr_ratio_vs_full == 0.9:  # Use all for training but test_size<=0 is not allowed\n",
    "                tr_data = tr_data_all.copy()\n",
    "            else:\n",
    "                discard_size = 1 - (tr_ratio_vs_full / (1 - te_ratio_vs_full))\n",
    "                tr_data, _ = train_test_split(tr_data_all, test_size=discard_size, random_state=seed+rep+1, \n",
    "                                              shuffle=True)\n",
    "\n",
    "            cv_data = {'full': {'tr': tr_data, 'te': te_data}}\n",
    "            for cv_key, (train_cv, valid_cv) in enumerate(KFold(10, random_state=seed+rep, shuffle=True).split(tr_data)):\n",
    "                cv_data[cv_key] = {'tr': tr_data.iloc[train_cv], 'te': tr_data.iloc[valid_cv]}\n",
    "\n",
    "            for cv_key, data in cv_data.items():\n",
    "                train_cv = data['tr']\n",
    "                valid_cv = data['te']\n",
    "                valid_cv['cv'] = cv_key\n",
    "\n",
    "                # Add residues only available in the validation data. This is necessary for certain models when the data \n",
    "                # is exremely sparse.\n",
    "                va_only_pos = set(valid_cv.position) - set(train_cv.position)\n",
    "                if len(va_only_pos) > 0:\n",
    "                    va_only_wt = valid_cv.query(\"position in @va_only_pos\")[['dms_id', 'position', 'u_pos',\n",
    "                                                                             'aa1']].drop_duplicates().copy()\n",
    "                    va_only_wt['aa2'] = va_only_wt['aa1']\n",
    "                    va_only_wt['score'] = 1\n",
    "                    train_cv_va_wt = pd.concat([train_cv, va_only_wt], ignore_index=True)\n",
    "                    mask_mat = util.create_dms_score_matrix(train_cv_va_wt, 1)\n",
    "                else:\n",
    "                    train_cv_va_wt = train_cv.copy()\n",
    "                    mask_mat = util.create_dms_score_matrix(train_cv, 1)\n",
    "\n",
    "                # Individual imputation methods.\n",
    "                for method in ['envision', 'wu2019', 'lasso', 'fdms', 'row-mean']:\n",
    "                    if method == 'envision':\n",
    "                        estimator = GradientBoostingRegressor(random_state=seed+rep)\n",
    "                        gs = GridSearchCV(estimator, env_params)\n",
    "                        estimator = gs.fit(train_cv[env_encfeat], train_cv['score']).best_estimator_\n",
    "                        valid_cv['envision_pred'] = estimator.predict(valid_cv[env_encfeat])\n",
    "                        if cv_key == 'full':\n",
    "                            top_feat = list(pd.Series(dict(zip(env_encfeat, \n",
    "                                                               estimator.feature_importances_))).sort_values().tail(10).index)\n",
    "                            ens_feat = basic_ens_feat + top_feat\n",
    "\n",
    "                    elif method == 'wu2019':\n",
    "                        uniprot_id = train_cv['uniprot_id'].iloc[0]\n",
    "                        if uniprot_id not in wu_ava_unip:\n",
    "                            valid_cv['wu2019_pred'] = 1  # Can not be imputed so just set wildtype arbitrarily.\n",
    "                        else:\n",
    "                            imp_result = foo_wu2019_wrapping_func_23031601(train_cv_va_wt, f\"{sess_prefix}_{dms}_{rep}_{cv_key}\")\n",
    "                            imp_result = imp_result.rename(columns={'pred_score': 'wu2019_pred'})\n",
    "                            valid_cv = pd.merge(valid_cv, imp_result, on=['u_pos', 'aa2'], how='left', validate='1:1')\n",
    "\n",
    "                    else:\n",
    "                        if method == 'lasso':\n",
    "                            imp_mat = linear_collaborative_filtering_on_rows_lasso(mask_mat, 'ACDEFGHIKLMNPQRSTVWY', \n",
    "                                                                                   0.01, seed+rep)\n",
    "                        elif method == 'fdms':\n",
    "                            imp_mat = impute_by_matrix_factorisation(mask_mat, seed+rep, 100, n_components=2, \n",
    "                                                                               regularization=1)\n",
    "                        elif method == 'row-mean':\n",
    "                            null_mat = mask_mat.copy()\n",
    "                            null_mat.loc[:,:] = np.nan\n",
    "                            imp_mat = null_mat.T.fillna(mask_mat.mean(axis=1)).T\n",
    "                        else:\n",
    "                            raise ValueError()\n",
    "                        imp_long = imp_mat.reset_index().melt(id_vars=['dms_id', 'position'], value_name=f\"{method}_pred\", \n",
    "                                                              var_name='aa2')\n",
    "                        valid_cv = pd.merge(valid_cv, imp_long, on=['dms_id', 'position', 'aa2'], how='left', validate='1:1')\n",
    "\n",
    "                cv_data[cv_key]['te'] = valid_cv\n",
    "\n",
    "            # Ensemble method.\n",
    "            tr_pred = pd.concat([cv_data[i]['te'] for i in range(10)], ignore_index=True)\n",
    "            te_pred = cv_data['full']['te']\n",
    "            estimator = RandomForestRegressor(random_state=seed+rep, n_jobs=2)\n",
    "            gs = GridSearchCV(estimator, ens_params)\n",
    "            estimator = gs.fit(tr_pred[ens_feat], tr_pred['score']).best_estimator_\n",
    "            tr_pred['pred_score'] = estimator.predict(tr_pred[ens_feat])\n",
    "            te_pred['pred_score'] = estimator.predict(te_pred[ens_feat])\n",
    "\n",
    "            te_pred.to_csv(f\"{output_dir}{tr_ratio_vs_full}_{dms}_{rep}_enstest_data.csv\")\n",
    "            tuned_hp = pd.Series(estimator.get_params()).loc[list(ens_params.keys())]\n",
    "            tuned_hp.to_csv(f\"{output_dir}{tr_ratio_vs_full}_{dms}_{rep}_enstrain_hp.csv\")\n",
    "            imp = pd.Series(dict(zip(ens_feat, estimator.feature_importances_)))\n",
    "            imp.to_csv(f\"{output_dir}{tr_ratio_vs_full}_{dms}_{rep}_enstrain_imp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43717151",
   "metadata": {},
   "source": [
    "### Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ddb80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdir = '../result/train_proportion/'\n",
    "ens_comp_perf = []\n",
    "for file in os.listdir(wkdir):\n",
    "    if file[-len('enstest_data.csv'):] != 'enstest_data.csv':\n",
    "        continue\n",
    "    compl, dms, rep, _, _ = file.split('_')\n",
    "    data = pd.read_csv(f\"{wkdir}{file}\", index_col=0)\n",
    "    row = {'dms_id': dms, 'repeat': rep, 'completeness': compl}\n",
    "    for col in ['envision_pred', 'wu2019_pred', 'lasso_pred', 'fdms_pred', 'row-mean_pred', 'pred_score']:\n",
    "        row[col] = pearsonr(data[col], data['score'])[0]\n",
    "    ens_comp_perf.append(row)\n",
    "ens_comp_perf = pd.DataFrame(ens_comp_perf)\n",
    "#ens_comp_perf.to_csv('../result/train_proportion/performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7b368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
